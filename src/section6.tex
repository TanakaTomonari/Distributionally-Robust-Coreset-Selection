
\section{Conclusions}
\label{sec:conclusions}

%
In this paper, we proposed DRCS as a robust coreset selection method when the data distribution in deployment environment is uncertain.
%
The proposed DRCS method effectively reduces data storage and model update costs in a DR learning environment.
%
Our technical contribution is deriving an upper bound of the worst-case weighted validation error under covariate shift,
%
and then, we perform coreset selection aimed at minimizing this upper bound.
%
As a result, the upper bound of the test error under future uncertain covariate shift was estimated, and its theoretical guarantee was provided.
%
Furthermore, the effectiveness of the proposed DRCS method was also demonstrated in the experiments.

We are thinking of the following possible future directions.
%
\red{
%
One is the application to the regression problems or multi-class classification problems.
Although the computation of the upper bound of the validation error become different, we believe that the same strategy is available.
%
Another is the extension to {\em dataset distillation}, which allows not only removing samples but also newly creating samples that gives similar model parameters to that by the original dataset.
%
Also, a part of existing methods \citep{munteanu2018coresets,tukan2020coresets,tuka2021coresets,tolochinksy2022generic,alishahi2024dimensional} 
imply two possible future directions:
%
One is that, since a part of coreset selection methods allows us not only to select coresets but also weight the selected samples, we consider extending our method to employ the strategy.
%
The other is that, since these methods provide probabilistic guarantee in the performance, we consider deriving the performance guarantee of our method. Since current upper bound of the validation error in the proposed method is deterministic and therefore tends to be loose, probabilistic analysis may help this.
%
}
